# generate_eps.py
import json
from io import StringIO
from pathlib import Path

import pandas as pd
import requests
from bs4 import BeautifulSoup

STOCK_IDS = ["2330", "2317", "2303"]

# åŠ å¼·ä¸€é» Headerï¼ˆå« Refererï¼‰ï¼Œå¦å¤–å¸¶ä¸Šä¸€äº› cookieï¼ˆä¸ä¸€å®šæ¯æ¬¡éƒ½è¦ï¼Œä½†åœ¨ CI æ¯”è¼ƒå®¹æ˜“æˆåŠŸï¼‰
HEADERS = {
    "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36",
    "Accept-Language": "zh-TW,zh;q=0.9,en;q=0.8",
    "Referer": "https://goodinfo.tw/tw/index.asp",
    "Cookie": "IS_TOUCH_DEVICE=F; SCREEN_SIZE=WIDTH=2048&HEIGHT=1280;",
}

def fetch_eps(stock_id: str, debug_dir: Path) -> list[dict]:
    url = f"https://goodinfo.tw/tw/StockBzPerformance.asp?STOCK_ID={stock_id}"
    r = requests.get(url, headers=HEADERS, timeout=25)
    r.raise_for_status()
    r.encoding = "utf-8"

    # å­˜åŸå§‹é é¢ï¼Œæ–¹ä¾¿åœ¨ Actions ä¸‹è¼‰æª¢æŸ¥
    (debug_dir / f"page_{stock_id}.html").write_text(r.text, "utf-8")

    soup = BeautifulSoup(r.text, "lxml")
    container = soup.select_one("#txtFinDetailData")
    if not container:
        print(f"âš ï¸ æ‰¾ä¸åˆ°å¤–å±¤ #txtFinDetailData for {stock_id}")
        return []

    # å–å…§å±¤çœŸæ­£çš„ tableï¼ˆæœ‰äº›æƒ…æ³ container è£¡ä¸æ­¢ä¸€å±¤ï¼‰
    table = container.find("table")
    if not table:
        print(f"âš ï¸ æ‰¾ä¸åˆ°å…§å±¤ <table> for {stock_id}")
        return []

    (debug_dir / f"table_{stock_id}.html").write_text(str(table), "utf-8")

    # ç”¨ StringIO åŒ… table çµ¦ pandas è®€
    dfs = pd.read_html(StringIO(str(table)))
    if not dfs:
        print(f"âš ï¸ pandas.read_html è®€ä¸åˆ°è¡¨ for {stock_id}")
        return []

    df = dfs[0]
    # æŠŠå¤šå±¤æ¬„ä½å£“å¹³ï¼Œé¿å… MultiIndex æˆ–å¥‡æ€ªç©ºç™½
    df.columns = [str(c).strip().replace("\n", "").replace(" ", "") for c in df.columns]

    # åµéŒ¯ï¼šè¼¸å‡ºæ¬„ä½åç¨±èˆ‡å‰å¹¾åˆ—
    (debug_dir / f"df_cols_{stock_id}.txt").write_text("\n".join(df.columns), "utf-8")
    try:
        (debug_dir / f"df_head_{stock_id}.csv").write_text(df.head(10).to_csv(index=False), "utf-8")
    except Exception:
        pass

    # å˜—è©¦ç”¨å¹¾ç¨®å¯èƒ½çš„æ¬„ä½å
    year_keys = ["å¹´åº¦", "å¹´/å­£", "å¹´/å­£åº¦", "å¹´å­£"]
    eps_keys  = ["EPS(å…ƒ)", "ç¨…å¾ŒEPS(å…ƒ)", "æ¯è‚¡ç›ˆé¤˜(å…ƒ)"]
    yoy_keys  = ["å¹´å¢(å…ƒ)", "å¹´å¢ç‡(%)", "å¹´å¢ç‡"]
    pe_keys   = ["æœ¬ç›Šæ¯”", "æœ¬ç›Šæ¯”(å€)"]

    def pick(row, keys):
        for k in keys:
            k_norm = k.replace(" ", "").replace("\n", "")
            if k_norm in row:
                val = row.get(k_norm)
                if pd.notna(val):
                    return str(val)
        return ""

    rows = []
    for _, row in df.iterrows():
        # å°‡ç´¢å¼•è½‰ dictï¼Œä¸¦æŠŠ key æ­£è¦åŒ–å¾ŒæŸ¥æ‰¾
        rdict = {str(k).strip().replace("\n", "").replace(" ", ""): row[k] for k in df.columns if k in row}
        item = {
            "year": pick(rdict, year_keys),
            "eps":  pick(rdict, eps_keys),
            "yoy":  pick(rdict, yoy_keys),
            "pe":   pick(rdict, pe_keys),
        }
        # éæ¿¾å®Œå…¨ç©ºç™½çš„åˆ—
        if any(item.values()):
            rows.append(item)

    return rows

def main():
    debug_dir = Path("debug")
    debug_dir.mkdir(exist_ok=True)

    cache = {}
    for sid in STOCK_IDS:
        try:
            data = fetch_eps(sid, debug_dir=debug_dir)
            cache[sid] = data
            print(f"âœ… å®Œæˆ {sid}ï¼ˆå…± {len(data)} ç­†ï¼‰")
        except Exception as e:
            print(f"âŒ å¤±æ•— {sid}: {e}")
            cache[sid] = []

    Path("eps_cache.json").write_text(json.dumps(cache, ensure_ascii=False, indent=2), "utf-8")
    print("ğŸ“ eps_cache.json å„²å­˜å®Œæˆï¼")

if __name__ == "__main__":
    main()
